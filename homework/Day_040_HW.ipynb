{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 練習時間\n",
    "試著使用 sklearn datasets 的其他資料集 (boston, ...)，來訓練自己的線性迴歸模型，並加上適當的正則話來觀察訓練情形。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plot\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fnLinearRegression(x_train, x_test, y_train, y_test):\n",
    "    linear = linear_model.LinearRegression()\n",
    "    linear.fit(x_train, y_train)\n",
    "    y_pred = linear.predict(x_test)\n",
    "    return (mean_squared_error(y_test, y_pred))\n",
    "\n",
    "def fnRegression(x_train, x_test, y_train, y_test, model, alpha):\n",
    "    if (model == \"Lasso\"):\n",
    "        Regression = linear_model.Lasso(alpha)\n",
    "    elif (model == \"Ridge\"):\n",
    "        Regression = linear_model.Ridge(alpha)\n",
    "    else:\n",
    "        print(\"Invail Value\")\n",
    "        return\n",
    "    Regression.fit(x_train, y_train)\n",
    "    y_pred = Regression.predict(x_test)\n",
    "    return (mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "boston = datasets.load_boston()\n",
    "\n",
    "b_x_train, b_x_test, b_y_train, b_y_test = train_test_split(boston.data, boston.target, test_size=0.1, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:Boston\n",
      "\n",
      "LinearRegression Mean Squared error: 17.032\n",
      "\n",
      "Min Mean Squared error by using Lasso: 18.18040716055948\n",
      "Min Mean Squared error by using Ridge: 17.058985804204816\n"
     ]
    }
   ],
   "source": [
    "Lasso_errors = []\n",
    "Ridge_errors = []\n",
    "\n",
    "print(\"Case:Boston\\n\")\n",
    "\n",
    "lin_error = fnLinearRegression(b_x_train, b_x_test, b_y_train, b_y_test)\n",
    "print(\"LinearRegression Mean Squared error: %.3f\\n\" % lin_error)\n",
    "\n",
    "for alpha in np.arange(0, 10, 0.1):\n",
    "    Lasso_errors.append(fnRegression(b_x_train, b_x_test, b_y_train, b_y_test, model=\"Lasso\", alpha=0.1))\n",
    "    Ridge_errors.append(fnRegression(b_x_train, b_x_test, b_y_train, b_y_test, model=\"Ridge\", alpha=0.1))\n",
    "\n",
    "print(f'Min Mean Squared error by using Lasso: {min(Lasso_errors)}')\n",
    "print(f'Min Mean Squared error by using Ridge: {min(Ridge_errors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine = datasets.load_wine()\n",
    "\n",
    "w_x_train, w_x_test, w_y_train, w_y_test = train_test_split(wine.data, wine.target, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:Wine\n",
      "\n",
      "LinearRegression Mean Squared error: 0.067\n",
      "\n",
      "Min Mean Squared error by using Lasso: 0.10175180481909947\n",
      "Min Mean Squared error by using Ridge: 0.06709604906317543\n"
     ]
    }
   ],
   "source": [
    "Lasso_errors = []\n",
    "Ridge_errors = []\n",
    "\n",
    "print(\"Case:Wine\\n\")\n",
    "\n",
    "lin_error = fnLinearRegression(w_x_train, w_x_test, w_y_train, w_y_test)\n",
    "print(\"LinearRegression Mean Squared error: %.3f\\n\" % lin_error)\n",
    "\n",
    "for alpha in np.arange(0, 10, 0.1):\n",
    "    Lasso_errors.append(fnRegression(w_x_train, w_x_test, w_y_train, w_y_test, model=\"Lasso\", alpha=0.1))\n",
    "    Ridge_errors.append(fnRegression(w_x_train, w_x_test, w_y_train, w_y_test, model=\"Ridge\", alpha=0.1))\n",
    "\n",
    "print(f'Min Mean Squared error by using Lasso: {min(Lasso_errors)}')\n",
    "print(f'Min Mean Squared error by using Ridge: {min(Ridge_errors)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "linnerud = datasets.load_linnerud()\n",
    "\n",
    "l_x_train, l_x_test, l_y_train, l_y_test = train_test_split(linnerud.data, linnerud.target, test_size=0.2, random_state=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case:Linnerud\n",
      "\n",
      "LinearRegression Mean Squared error: 386.152\n",
      "\n",
      "Min Mean Squared error by using Lasso: 349.62875522033823\n",
      "Min Mean Squared error by using Ridge: 377.53996796861276\n"
     ]
    }
   ],
   "source": [
    "Lasso_errors = []\n",
    "Ridge_errors = []\n",
    "\n",
    "print(\"Case:Linnerud\\n\")\n",
    "\n",
    "lin_error = fnLinearRegression(l_x_train, l_x_test, l_y_train, l_y_test)\n",
    "print(\"LinearRegression Mean Squared error: %.3f\\n\" % lin_error)\n",
    "\n",
    "for alpha in np.arange(0, 10, 0.1):\n",
    "    Lasso_errors.append(fnRegression(l_x_train, l_x_test, l_y_train, l_y_test, model=\"Lasso\", alpha=50))\n",
    "    Ridge_errors.append(fnRegression(l_x_train, l_x_test, l_y_train, l_y_test, model=\"Ridge\", alpha=50))\n",
    "\n",
    "\n",
    "fnLinearRegression(l_x_train, l_x_test, l_y_train, l_y_test)\n",
    "fnRegression(l_x_train, l_x_test, l_y_train, l_y_test, model=\"Lasso\", alpha=50)\n",
    "fnRegression(l_x_train, l_x_test, l_y_train, l_y_test, model=\"Ridge\", alpha=50)\n",
    "\n",
    "print(f'Min Mean Squared error by using Lasso: {min(Lasso_errors)}')\n",
    "print(f'Min Mean Squared error by using Ridge: {min(Ridge_errors)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusionn\n",
    "* 三組對照 Datasets:1. Boston house-prices, 2. Wine, and 3. Linnerud.\n",
    "* 使用alpha 為 0 - 10，間距為 0.1 進行測試，根據測試結果，只有使用 Linnerud 的 Datastes 得到比較好的結果，對照 Datastes 的說明，Boston house-prices 與 Wine 均為簡單的 regression 問題，而 Linnerud 為 multivariate regression 問題，因此驗證了一昧使用 Lasso/Ridge 並不會使結果變得更好，要事先分析是否為 overfitting/multivariate 的情況。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
